{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixture Model\n",
    "\n",
    "GMM is a soft cluster algorithm, which means that every point will belong to every cluster, but with different levels of membership.\n",
    "\n",
    "Most real life datasets can be approximated to a Gaussian Distribution, and what this algorithm does is cluster points according to a Gaussian Distribution that generated them.\n",
    "\n",
    "<br><img src=\"images/gaussian-mixture-model.png\" width=\"720px\"><br>\n",
    "\n",
    "01. **Initialize Gaussian Distributions**: To initialize, we need to give them initial values, of mean and standard deviation. The naive way to the give them the average and the mean of the dataset itself, but in practice we run K-Means on the dataset and use the clusters produced to initialize the Gaussian Distributions. In the example, we'll use random values for the mean and variance - which is just the standard deviation squared!\n",
    "\n",
    "<br><img src=\"images/expectation-maximization-1.png\" width=\"720px\"><br>\n",
    "\n",
    "Note that in the image we're representing the standard deviation, but in calculations we use variance.\n",
    "\n",
    "02. **Soft cluster the data points - \"Expectation\" step**: In this step, we calculate the membership of each point to each cluster we have. Intuitivelly we look at a point at tell if a points is closer to one cluster or another, but we can calculate this, using the probability density function for a normal distribution.\n",
    "\n",
    "<br><img src=\"images/expectation-maximization-2.png\" width=\"720px\"><br>\n",
    "\n",
    "03. **Re-estimate parameters of Gaussians - \"Maximization\" step**: Now, we that the products of the previous step and calculate new means and standard deviations for the Gaussians. We can see the clusters will begin to move and we repeat this step until they finally converge and produce a better result.\n",
    "\n",
    "<br>\n",
    "<img src=\"images/expectation-maximization-3.1.png\" width=\"480px\" style=\"float: left\">\n",
    "<img src=\"images/expectation-maximization-3.2.png\" width=\"480px\" style=\"float: right\">\n",
    "<div style=\"clear: both\"></div>\n",
    "<br>\n",
    "\n",
    "04. **Evaluate log-likelihood**: The final step is to calculate the log-likelihood. Basically, the higher the number, the more sure we are that the mixture model generated the dataset.\n",
    "\n",
    "<br><img src=\"images/expectation-maximization-4.png\" width=\"720px\"><br>\n",
    "\n",
    "## Cluster validation\n",
    "\n",
    "There are three categories of indices used to evaluate the clusters produced by a clustering algorithm:\n",
    "\n",
    "* External: Scoring method used when the original data is labeled.\n",
    "* Internal: Measure the fit between the data and structure using only the data.\n",
    "* Relative: Indicate which of two cluster structures is better on some datasets.\n",
    "\n",
    "Most of these indices are defined in terms of compactness and separability, which are a measure of how close the elements of a cluster are to each other, and how far/distinct two clusters are to each other, respectively.\n",
    "\n",
    "### Silhouette index\n",
    "\n",
    "One internal index used to validate clustering algorithms is the silhouette index, which is calculated by measuring the distance between a point and other points in the same cluster, and points in the closest cluster:\n",
    "\n",
    "<br><img src=\"images/silhouette-index.png\" width=\"720px\"><br>\n",
    "\n",
    "One of the applications of this index, is finding the optimal number of clusters (k):\n",
    "\n",
    "<br>\n",
    "<img src=\"images/silhouette-finding-k.png\" width=\"720px\">\n",
    "<br>\n",
    "<img src=\"images/silhouette-finding-k-graph.png\" width=\"720px\">\n",
    "<br>\n",
    "\n",
    "Another application is comparing different algorithms and choosing the best one:\n",
    "\n",
    "<br>\n",
    "<img src=\"images/silhouette-comparing-algorithms-1.png\" width=\"720px\">\n",
    "<br>\n",
    "<img src=\"images/silhouette-comparing-algorithms-2.png\" width=\"720px\">\n",
    "<br>\n",
    "\n",
    "But there's a caveat! It's good for compact/dense clusters. Ring-shaped ones get an awful result:\n",
    "\n",
    "<br><img src=\"images/silhouette-comparing-algorithms-3.png\" width=\"720px\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
